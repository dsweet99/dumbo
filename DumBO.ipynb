{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import dumbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DumBO\n",
    "\n",
    "Teach the basic concepts of BO by building a simplistic optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find the value of `x` that maximizes the function, `y(x)`, as \n",
    "defined by `measure()`, below. This may be called *objective function*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(x):\n",
    "    return float(1 - .0950 + (\n",
    "        -(((x - .3333)**2).mean())\n",
    "        + .1*np.sin(30*x).mean()\n",
    "        + .01*np.random.normal()\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Bayesian optimization setting it is *expensive* -- in dollars, time, risk, labor, etc. --\n",
    "to measure `y(x)` as a value `x`. Therefore, we try to take as few measurements as possible.\n",
    "\n",
    "Typically measurements are uncertain -- they're *noisy*. We simulate measurement noise in `measure()` by adding `.01*np.random.normal()` to the function value.\n",
    "\n",
    "Note, also, that we don't know the derivative of `y(x)`. We only know measured function values. This property makes the problem a *black-box* optimization problem.\n",
    "\n",
    "In summary, Bayesian optimization is said to perform black-box optimization of noisy, expensive objectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surrogate(x_m, y_m, x):\n",
    "    distance = np.sqrt( ((x - x_m)**2) )\n",
    "    i = np.argmin(distance)\n",
    "    y_ex = y_m[i]\n",
    "    y_var = distance[i]\n",
    "    return y_ex, y_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquisition_function(y_ex, y_var):\n",
    "    return y_ex + np.sqrt(y_var)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(x_m, y_m):\n",
    "    x = np.linspace(0,1,1000)\n",
    "    af = np.array([acquisition_function(*surrogate(x_m, y_m, xx)) for xx in x])\n",
    "    i = np.argmax(af)\n",
    "    return x[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_surrogate(ax, x_m, y_m):\n",
    "    x = np.linspace(0,1,30)\n",
    "    ev = np.array([surrogate(x_m, y_m, xx) for xx in x])\n",
    "    y_ex = ev[:,0]\n",
    "    y_se = np.sqrt(ev[:,1])\n",
    "    \n",
    "    ax.plot(x_m, y_m, 'o');\n",
    "    ax.plot(x, y_ex, '--');\n",
    "\n",
    "    ax.fill_between(\n",
    "        x,\n",
    "        y_ex - y_se,\n",
    "        y_ex + y_se,\n",
    "        alpha=.5,\n",
    "    linewidth=1\n",
    "    );\n",
    "    \n",
    "def vline(ax, x0, color='black'):\n",
    "    c = ax.axis()\n",
    "    ax.autoscale(False)\n",
    "    ax.plot([x0, x0], [c[2], c[3]], '--', linewidth=1, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = ( 1 + np.sqrt(5) ) / 2 # the golden ratio, for plots\n",
    "y_best = 0\n",
    "x_m = np.array([.5])\n",
    "y_m = np.array([measure(xx) for xx in x_m])\n",
    "\n",
    "trace = [y_m[0]]\n",
    "for _ in range(15):\n",
    "    x = optimize(x_m, y_m)\n",
    "    y = measure(x)\n",
    "    x_m = np.append(x_m, x)\n",
    "    y_m = np.append(y_m, y)\n",
    "    trace.append(y_m.max())\n",
    "    \n",
    "    xlabel = 'number of measurements'\n",
    "    width = 10\n",
    "    clear_output(wait=True)\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(width, width/phi/phi))\n",
    "    plot_surrogate(ax1, x_m, y_m)\n",
    "    x_max = x_m[np.argmax(y_m)]\n",
    "    ax1.set_title(f\"x_max = {x_max:.4f}\")\n",
    "    vline(ax1, x_max)\n",
    "    ax1.set_xlabel(xlabel)\n",
    "    ax2.plot(trace, '--');\n",
    "    ax2.plot(y_m, '.k', alpha=.5);\n",
    "    ax2.set_title(f'y_max = {y_m.max():.4f}')\n",
    "    ax2.set_xlabel(xlabel)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    time.sleep(.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "\n",
    "np.random.seed(17)\n",
    "digits = load_digits()\n",
    "\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data, digits.target, test_size=1/2, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_test_accuracy(x):\n",
    "    x = x.flatten()\n",
    "    hp = {\n",
    "        'max_depth': int(1 + 7*x[0] + .5),\n",
    "        'subsample': x[1],\n",
    "        'min_child_weight': 1 + 99*x[2],\n",
    "        'colsample_bytree': x[3],\n",
    "        'eta': x[4],\n",
    "        'num_parallel_tree': int(1 + 9*x[5] + .5),\n",
    "    }\n",
    "    xgb_model = xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        **hp\n",
    "    )\n",
    "    xgb_model.fit(x_train, y_train)\n",
    "    return xgb_model.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dim = 6\n",
    "x_m = np.random.uniform(size=(1, num_dim))\n",
    "y_m = np.array([measure_test_accuracy(x_m)])\n",
    "\n",
    "y_best = y_m[0]\n",
    "x_best = x_m[0]\n",
    "trace = [y_best]\n",
    "print (y_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(20):\n",
    "    x = dumbo.optimize(x_m, y_m)\n",
    "    y = measure_test_accuracy(x)\n",
    "    x_m = np.append(x_m, x, axis=0)\n",
    "    y_m = np.append(y_m, y)\n",
    "    if y > y_best:\n",
    "        y_best = y\n",
    "        x_best = x\n",
    "    trace.append(y_best)\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(trace, 'k.--');\n",
    "    plt.title(f\"y_best = {y_best:.4f}\")\n",
    "    plt.xlabel('iterations')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
